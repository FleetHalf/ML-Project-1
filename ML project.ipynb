{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project 1\n",
    "## Comparing various machine learning techniques using the real estate data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Transaction date  House age  Distance to the nearest MRT station  \\\n",
      "0  2012-09-02 16:42:30.519336       13.3                            4082.0150   \n",
      "1  2012-09-04 22:52:29.919544       35.5                             274.0144   \n",
      "2  2012-09-05 01:10:52.349449        1.1                            1978.6710   \n",
      "3  2012-09-05 13:26:01.189083       22.2                            1055.0670   \n",
      "4  2012-09-06 08:29:47.910523        8.5                             967.4000   \n",
      "\n",
      "   Number of convenience stores   Latitude   Longitude  \\\n",
      "0                             8  25.007059  121.561694   \n",
      "1                             2  25.012148  121.546990   \n",
      "2                            10  25.003850  121.528336   \n",
      "3                             5  24.962887  121.482178   \n",
      "4                             6  25.011037  121.479946   \n",
      "\n",
      "   House price of unit area  \n",
      "0                  6.488673  \n",
      "1                 24.970725  \n",
      "2                 26.694267  \n",
      "3                 38.091638  \n",
      "4                 21.654710  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\AdityaTheEmp\\\\Desktop\\\\Projects\\\\Machine learning projects\\\\Comparing various machine learning models\\\\Real_Estate.csv\")\n",
    "#display the first few rows:\n",
    "data_head = data.head()\n",
    "print(data_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 7 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Transaction date                     414 non-null    object \n",
      " 1   House age                            414 non-null    float64\n",
      " 2   Distance to the nearest MRT station  414 non-null    float64\n",
      " 3   Number of convenience stores         414 non-null    int64  \n",
      " 4   Latitude                             414 non-null    float64\n",
      " 5   Longitude                            414 non-null    float64\n",
      " 6   House price of unit area             414 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 22.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#we shall now print the data info:\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler  # type: ignore\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the transaction column to datetime format:\n",
    "data['Transaction date'] = pd.to_datetime(data['Transaction date'])\n",
    "#dt.year extracts the year from the column entries, basically.\n",
    "data['Transaction year']= data['Transaction date'].dt.year\n",
    "#dt.month is the same but with months\n",
    "data['Transaction month'] = data['Transaction date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have extracted the relevant information into new columns, we shall drop the transaction date column:\n",
    "data = data.drop(columns = [\"Transaction date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the features and target variable:\n",
    "X = data.drop('House price of unit area', axis = 1)\n",
    "y = data['House price of unit area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `train_test_split` function, we are splitting the dataset into 20% testing and 80% training split.\n",
    "Next, we normaliza, or scale, the data in order to make it comparable and more standardized for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells us that the dimensions of the scaled training dataset is 331 rows and 7 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions of the test dataset are 83 rows and 7 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We shall now start with training multiple models and comparing their performance. These are the four models that we shall use:\n",
    "### 1. Linear regression\n",
    "### 2. Decision tree regressor\n",
    "### 3. Random forest resgressor\n",
    "### 4. Gradient boosting regressor\n",
    "\n",
    "### We will evaluate their performance using mean absolute error and R squared as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to hold the evaluation metrics for each model\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         MAE        R²\n",
      "Linear Regression   9.748246  0.529615\n",
      "Decision Tree      11.760342  0.204962\n",
      "Random Forest       9.887601  0.509547\n",
      "Gradient Boosting  10.000117  0.476071\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    # training the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # making predictions on the test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    # calculating evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # storing the metrics\n",
    "    results[name] = {\"MAE\": mae, \"R²\": r2}\n",
    "\n",
    "results_df = pd.DataFrame(results).T  # convert the results to a DataFrame for better readability\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, we first intitialize a dictionary of the four machine learning models that we are comparing. Then, in the loop, we are basically telling python to iterate through each model in the dictionary named model. The `fit()` function is used to fit the data to the specified models. Then we calculate the evaluation metrics and finally, store the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0d21b th {\n",
       "  background-color: black;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_0d21b td {\n",
       "  background-color: lightgrey;\n",
       "  color: black;\n",
       "}\n",
       "#T_0d21b tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_0d21b tr:nth-of-type(odd) {\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_0d21b tr:hover {\n",
       "  background-color: lightyellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0d21b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0d21b_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_0d21b_level0_col1\" class=\"col_heading level0 col1\" >R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d21b_level0_row0\" class=\"row_heading level0 row0\" >Linear Regression</th>\n",
       "      <td id=\"T_0d21b_row0_col0\" class=\"data row0 col0\" >9.748246</td>\n",
       "      <td id=\"T_0d21b_row0_col1\" class=\"data row0 col1\" >0.529615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d21b_level0_row1\" class=\"row_heading level0 row1\" >Decision Tree</th>\n",
       "      <td id=\"T_0d21b_row1_col0\" class=\"data row1 col0\" >11.760342</td>\n",
       "      <td id=\"T_0d21b_row1_col1\" class=\"data row1 col1\" >0.204962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d21b_level0_row2\" class=\"row_heading level0 row2\" >Random Forest</th>\n",
       "      <td id=\"T_0d21b_row2_col0\" class=\"data row2 col0\" >9.887601</td>\n",
       "      <td id=\"T_0d21b_row2_col1\" class=\"data row2 col1\" >0.509547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d21b_level0_row3\" class=\"row_heading level0 row3\" >Gradient Boosting</th>\n",
       "      <td id=\"T_0d21b_row3_col0\" class=\"data row3 col0\" >10.000117</td>\n",
       "      <td id=\"T_0d21b_row3_col1\" class=\"data row3 col1\" >0.476071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea22e509a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_table = results_df.style.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', 'black'), ('color', 'white'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'td', 'props': [('background-color', 'lightgrey'), ('color', 'black')]},\n",
    "    {'selector': 'tr:nth-of-type(even)', 'props': [('background-color', 'white')]},\n",
    "    {'selector': 'tr:nth-of-type(odd)', 'props': [('background-color', 'lightgrey')]},\n",
    "    {'selector': 'tr:hover', 'props': [('background-color', 'lightyellow')]},\n",
    "])\n",
    "\n",
    "# Display the styled table\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using AI, I tried to apply custom CSS to display the results in a better looking format. \n",
    "As seen from the results, it is evident that **Linear Regression** is the best model for the given dataset, with an $R^2$ value of 0.52. \n",
    "Decision Tree Regressor shows the highest MAE (11.76) and the lowest $R^2$ (0.20), indicating it may be overfitting to the training data and performing poorly on the test data. On the other hand, Random Forest Regressor and Gradient Boosting Regressor have similar MAEs (9.89 and 10.00, respectively) and $R^2$ scores (0.51 and 0.48, respectively), performing slightly worse than the Linear Regression model but better than the Decision Tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
